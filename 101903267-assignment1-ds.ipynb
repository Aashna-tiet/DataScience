{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T14:44:25.930135Z","iopub.execute_input":"2022-02-28T14:44:25.930391Z","iopub.status.idle":"2022-02-28T14:44:25.939546Z","shell.execute_reply.started":"2022-02-28T14:44:25.930364Z","shell.execute_reply":"2022-02-28T14:44:25.938799Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"We will first load dataset using cudf and then preprocess it so as to make the data usable.","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:22:14.670968Z","iopub.execute_input":"2022-02-28T06:22:14.671322Z","iopub.status.idle":"2022-02-28T06:22:24.345715Z","shell.execute_reply.started":"2022-02-28T06:22:14.671246Z","shell.execute_reply":"2022-02-28T06:22:24.344931Z"}}},{"cell_type":"code","source":"import cuml\nimport cupy as cp\nimport cudf\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:25.941222Z","iopub.execute_input":"2022-02-28T14:44:25.941958Z","iopub.status.idle":"2022-02-28T14:44:25.949620Z","shell.execute_reply.started":"2022-02-28T14:44:25.941903Z","shell.execute_reply":"2022-02-28T14:44:25.948863Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"df_train = cudf.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:25.997647Z","iopub.execute_input":"2022-02-28T14:44:25.997839Z","iopub.status.idle":"2022-02-28T14:44:26.274783Z","shell.execute_reply.started":"2022-02-28T14:44:25.997817Z","shell.execute_reply":"2022-02-28T14:44:26.273969Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_test  = cudf.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ndf_test","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.276618Z","iopub.execute_input":"2022-02-28T14:44:26.276891Z","iopub.status.idle":"2022-02-28T14:44:26.568156Z","shell.execute_reply.started":"2022-02-28T14:44:26.276854Z","shell.execute_reply":"2022-02-28T14:44:26.567496Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"raw","source":"\n","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.569911Z","iopub.execute_input":"2022-02-28T14:44:26.570315Z","iopub.status.idle":"2022-02-28T14:44:26.618742Z","shell.execute_reply.started":"2022-02-28T14:44:26.570278Z","shell.execute_reply":"2022-02-28T14:44:26.617976Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.620896Z","iopub.execute_input":"2022-02-28T14:44:26.621155Z","iopub.status.idle":"2022-02-28T14:44:26.656594Z","shell.execute_reply.started":"2022-02-28T14:44:26.621122Z","shell.execute_reply":"2022-02-28T14:44:26.655969Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"We want to remove all the features that hae null values more than 30 percent. We need features that can provide us with atkeats 70 percent of the data if not the features must be remoed as we wont be able to find replacements for null values and even if we did that might vary the results to great extent.","metadata":{}},{"cell_type":"code","source":"missing_from_df_train = df_train.isnull().sum()/len(df_train)\nmissing_from_df_train\nprint(\"The number of columns where loss is above 45 percent are : \")\n(missing_from_df_train>0.3).sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.657783Z","iopub.execute_input":"2022-02-28T14:44:26.658030Z","iopub.status.idle":"2022-02-28T14:44:26.692471Z","shell.execute_reply.started":"2022-02-28T14:44:26.657998Z","shell.execute_reply":"2022-02-28T14:44:26.691830Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"drop_from_train = missing_from_df_train[missing_from_df_train>0.3]\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.693807Z","iopub.execute_input":"2022-02-28T14:44:26.694318Z","iopub.status.idle":"2022-02-28T14:44:26.700170Z","shell.execute_reply.started":"2022-02-28T14:44:26.694284Z","shell.execute_reply":"2022-02-28T14:44:26.699424Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"We just dropped those 5 columns.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_train.drop(columns = drop_from_train.keys().to_array(),axis = 1, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.701545Z","iopub.execute_input":"2022-02-28T14:44:26.701804Z","iopub.status.idle":"2022-02-28T14:44:26.708504Z","shell.execute_reply.started":"2022-02-28T14:44:26.701761Z","shell.execute_reply":"2022-02-28T14:44:26.707780Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.709620Z","iopub.execute_input":"2022-02-28T14:44:26.710276Z","iopub.status.idle":"2022-02-28T14:44:26.749577Z","shell.execute_reply.started":"2022-02-28T14:44:26.710240Z","shell.execute_reply":"2022-02-28T14:44:26.748922Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df_train.reset_index(drop=True,inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.750933Z","iopub.execute_input":"2022-02-28T14:44:26.751709Z","iopub.status.idle":"2022-02-28T14:44:26.755416Z","shell.execute_reply.started":"2022-02-28T14:44:26.751675Z","shell.execute_reply":"2022-02-28T14:44:26.754720Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"We have two types of features categorical and numerical. For encoding purposes we need to know the number in which they are present or they might result in computational error.","metadata":{}},{"cell_type":"code","source":"categorical_features=[]\nfor cf in df_train.columns:\n    if(df_train[cf].dtype=='O'):\n        categorical_features.append(cf)\n        \n        \nprint(\"categorical_features : \",len(categorical_features))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.758853Z","iopub.execute_input":"2022-02-28T14:44:26.759322Z","iopub.status.idle":"2022-02-28T14:44:26.769760Z","shell.execute_reply.started":"2022-02-28T14:44:26.759294Z","shell.execute_reply":"2022-02-28T14:44:26.769050Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Since there are either categorical or numerical values, we got 38 categorical values so we are left with 38 numerical values as well. since numerical values are of two types : 1. continuos(Real numbers) 2. discrete (integers) and it is an integral part of preprocessing to know how many of each kind are present in case we apply an algorithm that works well only on discrete values. So we will count that too.","metadata":{}},{"cell_type":"code","source":"numerical_features=[]\nfor nf in df_train.columns:\n    if(df_train[nf].dtype!='O'):\n        numerical_features.append(nf)\n        \n        \nprint(\"numerical_features : \",len(numerical_features))\n\nyear_features = [feature for feature in numerical_features if 'Year' in feature or 'Yr' in feature ]\nyear_features","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.770743Z","iopub.execute_input":"2022-02-28T14:44:26.772614Z","iopub.status.idle":"2022-02-28T14:44:26.783327Z","shell.execute_reply.started":"2022-02-28T14:44:26.772582Z","shell.execute_reply":"2022-02-28T14:44:26.782658Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"\ndiscrete_features = [dft for dft in numerical_features if len(df_train[dft].unique()) < 25 and\n                     dft not in year_features]\nlen(discrete_features)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.784517Z","iopub.execute_input":"2022-02-28T14:44:26.784973Z","iopub.status.idle":"2022-02-28T14:44:26.818697Z","shell.execute_reply.started":"2022-02-28T14:44:26.784921Z","shell.execute_reply":"2022-02-28T14:44:26.817986Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"continuos_features  = [cft for cft in numerical_features if cft not in discrete_features and cft not in year_features]\nlen(continuos_features)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.819790Z","iopub.execute_input":"2022-02-28T14:44:26.820238Z","iopub.status.idle":"2022-02-28T14:44:26.826149Z","shell.execute_reply.started":"2022-02-28T14:44:26.820205Z","shell.execute_reply":"2022-02-28T14:44:26.825441Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.827461Z","iopub.execute_input":"2022-02-28T14:44:26.827921Z","iopub.status.idle":"2022-02-28T14:44:26.866992Z","shell.execute_reply.started":"2022-02-28T14:44:26.827887Z","shell.execute_reply":"2022-02-28T14:44:26.866289Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"for encoding we should find out the number of unique rows we are dealing with.\n","metadata":{}},{"cell_type":"code","source":"for feature in categorical_features:\n    print(f'The feature is {feature} and no of unique categories are {len(df_train[feature].unique())}')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.868048Z","iopub.execute_input":"2022-02-28T14:44:26.868260Z","iopub.status.idle":"2022-02-28T14:44:26.939593Z","shell.execute_reply.started":"2022-02-28T14:44:26.868230Z","shell.execute_reply":"2022-02-28T14:44:26.938892Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Now its time to encode the missing cateorical values and replace the ones in numerical category.\nWe have to first find out which columns have missing values and for that we will do isnull().sum() operation on every feature and find the percentage.\n\nIts upto us what we want to replace it with. We can remove categorical values with \"missing_values\" or any other string. But that all depends on the amount of data missing.","metadata":{}},{"cell_type":"code","source":"categorical_features_null_values= [feature for feature in df_train.columns if df_train[feature].isnull().sum() > 0 \n                                    and df_train[feature].dtype == 'O']\n\nfor feature in categorical_features_null_values :\n    print(f\"Amount of missing values in {feature} is {df_train[feature].isnull().sum()/len(df_train[feature])}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.941748Z","iopub.execute_input":"2022-02-28T14:44:26.942002Z","iopub.status.idle":"2022-02-28T14:44:26.993848Z","shell.execute_reply.started":"2022-02-28T14:44:26.941972Z","shell.execute_reply":"2022-02-28T14:44:26.992891Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"Since dataloss is less than 10 percent we can replace it with \"missing value\"","metadata":{}},{"cell_type":"code","source":"def replace_missing_categorical_features(dataset,features):\n    data = dataset.copy()\n    data[features] = data[features].fillna('Missing_values')\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:26.995060Z","iopub.execute_input":"2022-02-28T14:44:26.995284Z","iopub.status.idle":"2022-02-28T14:44:27.000600Z","shell.execute_reply.started":"2022-02-28T14:44:26.995254Z","shell.execute_reply":"2022-02-28T14:44:26.999684Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df_train = replace_missing_categorical_features(df_train, categorical_features)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.002518Z","iopub.execute_input":"2022-02-28T14:44:27.002716Z","iopub.status.idle":"2022-02-28T14:44:27.050379Z","shell.execute_reply.started":"2022-02-28T14:44:27.002694Z","shell.execute_reply":"2022-02-28T14:44:27.049730Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"we want to do the same with numerical values....but in case of numerical values we can't put zero as it may vary the results to great extent. so we replace it either wit mean, median or mode but mode seems a better option since house can have a feature similar to most of the others.","metadata":{}},{"cell_type":"code","source":"numerical_features_missing_values = [feature for feature in numerical_features if df_train[feature].isnull().sum() > 0]\nnumerical_features_missing_values\n\nfor feature in numerical_features_missing_values:\n    df_train[feature] = df_train[feature].fillna(df_train[feature].mode())\n   \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.051533Z","iopub.execute_input":"2022-02-28T14:44:27.051765Z","iopub.status.idle":"2022-02-28T14:44:27.127093Z","shell.execute_reply.started":"2022-02-28T14:44:27.051734Z","shell.execute_reply":"2022-02-28T14:44:27.126432Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"It is essential to scale the inputs so i used standard scaler.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from cuml.preprocessing import StandardScaler\ns = StandardScaler()\ndf_train[numerical_features]=s.fit_transform(df_train[numerical_features])\n\ndf_train[numerical_features]","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.128317Z","iopub.execute_input":"2022-02-28T14:44:27.128550Z","iopub.status.idle":"2022-02-28T14:44:27.275685Z","shell.execute_reply.started":"2022-02-28T14:44:27.128519Z","shell.execute_reply":"2022-02-28T14:44:27.274955Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from cuml.preprocessing import LabelEncoder\nenc = LabelEncoder()\nfor feature in categorical_features:\n    df_train[feature] = enc.fit_transform(df_train[feature])\n   \ndf_train[categorical_features].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.277005Z","iopub.execute_input":"2022-02-28T14:44:27.277241Z","iopub.status.idle":"2022-02-28T14:44:27.650001Z","shell.execute_reply.started":"2022-02-28T14:44:27.277209Z","shell.execute_reply":"2022-02-28T14:44:27.649336Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n    df_train[feature] = df_train['YrSold'] - df_train[feature]\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.651226Z","iopub.execute_input":"2022-02-28T14:44:27.651840Z","iopub.status.idle":"2022-02-28T14:44:27.657221Z","shell.execute_reply.started":"2022-02-28T14:44:27.651800Z","shell.execute_reply":"2022-02-28T14:44:27.656420Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.658577Z","iopub.execute_input":"2022-02-28T14:44:27.658844Z","iopub.status.idle":"2022-02-28T14:44:27.701912Z","shell.execute_reply.started":"2022-02-28T14:44:27.658811Z","shell.execute_reply":"2022-02-28T14:44:27.701156Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"chosing the important features will help make a better prediction.","metadata":{}},{"cell_type":"code","source":"df_train = df_train[[\"Street\",\"OpenPorchSF\",\"WoodDeckSF\",\"OverallQual\",\"YearBuilt\",\"YearRemodAdd\",\"ExterQual\",\"TotalBsmtSF\",\n                     \"1stFlrSF\",\"GrLivArea\",\"PoolArea\",\"Fireplaces\",\"RoofStyle\",\n                     \"FullBath\",\"TotRmsAbvGrd\",\"GarageCars\",\"GarageArea\",\n                   \"MSZoning\", \"Utilities\",\"BldgType\",\"Heating\",\"KitchenQual\",\"SaleCondition\",\"LandSlope\",\"SalePrice\"]]","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.703259Z","iopub.execute_input":"2022-02-28T14:44:27.703496Z","iopub.status.idle":"2022-02-28T14:44:27.708577Z","shell.execute_reply.started":"2022-02-28T14:44:27.703464Z","shell.execute_reply":"2022-02-28T14:44:27.707866Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_train.drop('SalePrice',axis=1)\nY = df_train['SalePrice']\nx_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.710058Z","iopub.execute_input":"2022-02-28T14:44:27.710522Z","iopub.status.idle":"2022-02-28T14:44:27.731929Z","shell.execute_reply.started":"2022-02-28T14:44:27.710487Z","shell.execute_reply":"2022-02-28T14:44:27.731261Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"y_valid.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.733226Z","iopub.execute_input":"2022-02-28T14:44:27.733455Z","iopub.status.idle":"2022-02-28T14:44:27.740254Z","shell.execute_reply.started":"2022-02-28T14:44:27.733424Z","shell.execute_reply":"2022-02-28T14:44:27.739421Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"from cuml.linear_model import LinearRegression\n\nalgo = ['svd', 'eig', 'qr', 'svd-qr', 'svd-jacobi']\n\nfor i in algo: \n    lr = LinearRegression(fit_intercept = True, normalize = False,\n                      algorithm = i)\n\n    reg = lr.fit(x_train,y_train)\n\n    print(reg.coef_)\n\n    preds=lr.predict(x_valid)\n    \n    print(preds)\n    \n    MSE=cuml.metrics.regression.mean_squared_error(y_valid,preds)\n    MAE=cuml.metrics.regression.mean_absolute_error(y_valid,preds)\n    R2_Score=cuml.metrics.regression.r2_score(y_valid,preds)\n    \n\n    print(f\"for algo {i} MSE is {MSE}  MAE is {MAE} r2_score is {R2_Score}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:44:27.741784Z","iopub.execute_input":"2022-02-28T14:44:27.742164Z","iopub.status.idle":"2022-02-28T14:44:27.856970Z","shell.execute_reply.started":"2022-02-28T14:44:27.742128Z","shell.execute_reply":"2022-02-28T14:44:27.856197Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}